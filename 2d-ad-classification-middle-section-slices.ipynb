{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8086625,"sourceType":"datasetVersion","datasetId":4773615},{"sourceId":8221702,"sourceType":"datasetVersion","datasetId":4874179},{"sourceId":8293124,"sourceType":"datasetVersion","datasetId":4881634}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **2D Binary Classification Models for Alzheimer using middle section slicing**","metadata":{}},{"cell_type":"markdown","source":"# (1) Import the necessary packages","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport time\nfrom scipy.ndimage import zoom\nimport csv\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn.init as init\nfrom torch import optim\n\nimport numpy as np\nimport nibabel as nib\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom glob import glob\nimport torch\nfrom skimage.measure import label, regionprops\nfrom scipy.ndimage.morphology import binary_fill_holes\nimport scipy\nfrom sklearn.metrics import roc_curve, auc\nimport nibabel as nib\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check that CPU is available \ncuda = torch.cuda.is_available()\nprint(\"GPU available:\", cuda)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Set random seed for reproducibility\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (2) Data Exploration","metadata":{}},{"cell_type":"markdown","source":"### Load sample","metadata":{}},{"cell_type":"code","source":"# Load the NIfTI file\ntest_path = '/kaggle/input/preprocessed-data/ADNI_large_sample/validation/T1_affine/AD/ADNI_005_S_0929_MPR_m06_g_AD_dx_3_age_82.7_scan0_mri_brainmask_mni152brain_affine_tl.nii'\ntest_img = nib.load(test_path)\n\n# Extract the data\ndata = test_img.get_fdata()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the start and end indices for the middle two-thirds of the second dimension (height)\nheight = data.shape[1]\nstart_slice = height // 3\nend_slice = height * 2 // 3\n\n# Determine how many consecutive 3-slice sets can be made\n# Here, we subtract 2 to ensure that we have enough slices to form the last 3-channel set\nnumber_of_2d_images = (end_slice - start_slice - 2) // 3\nnumber_of_2d_images = number_of_2d_images*(386+405)\n\nprint(f\"Number of 2D images with 3 channels: {number_of_2d_images}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize 3D and print dimensions","metadata":{}},{"cell_type":"code","source":"# Get dimensions\nheight, width, length = data.shape\nprint(\"Height:\", height)\nprint(\"Width:\", width)\nprint(\"Length:\", length)\n\n# Visualize the MRI data\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx, y, z = data.nonzero()\nax.scatter(x, y, z, zdir='z', c='red', marker='o', s=1, alpha=0.1)\nplt.title('3D Visualization of MRI Data')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize 2D three axis and print dimensions","metadata":{}},{"cell_type":"code","source":"data.max(), data.min()\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10,5))\n# Coronal\nax1.imshow(data[:,109,:], cmap='gray')\n# Axial\nax2.imshow(data[:,:,91], cmap='gray')\n# Sagittal\nax3.imshow(data[91,:,:], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (3) Upload data and create data loader","metadata":{}},{"cell_type":"markdown","source":"### Define MRIDataset class","metadata":{}},{"cell_type":"code","source":"class MRIDataset(Dataset):\n    def __init__(self, DataDir, mode, input_T1, transform=None, T1_normalization_method='max', downsample=2.5):\n        self.DataDir = DataDir\n        self.input_T1 = input_T1\n        if input_T1:\n            self.T1_img_files = sorted(glob(DataDir + 'T1_affine/*/*.nii'))\n            print(f'T1 path: {DataDir}T1_affine')\n            print(f'Load T1. Total T1 {mode} number is: ' + str(len(self.T1_img_files)))\n        self.transform = transform\n        self.T1_normalization_method = T1_normalization_method\n        self.downsample = downsample\n\n    def __len__(self):\n        return len(self.T1_img_files)\n\n    def resample_img(self, arr, val=2):\n        return zoom(arr, (1/val, 1/val, 1/val))\n    \n    def __getitem__(self, idx):\n        path = self.T1_img_files[idx]\n        label = path.split('/')[-2]\n        label = 1 if label == 'AD' else 0\n        mri_data = nib.load(path).get_fdata().astype(np.float32)\n\n        if self.T1_normalization_method == 'max' and mri_data.max() > 0:\n            mri_data /= mri_data.max()\n        \n        if self.downsample:\n            mri_data = self.resample_img(mri_data, self.downsample)\n\n        # Select slices from the middle two-thirds of the second dimension\n        start_slice = mri_data.shape[1] // 3\n        end_slice = mri_data.shape[1] * 2 // 3\n        relevant_slices = mri_data[:, start_slice:end_slice, :]\n        \n        # Create 3-channel 2D images from consecutive slices\n        images = []\n        for i in range(0, relevant_slices.shape[1] - 2, 3):\n            img_stack = np.stack([\n                relevant_slices[:, i, :],\n                relevant_slices[:, i+1, :],\n                relevant_slices[:, i+2, :]\n            ], axis=-1)\n            images.append(img_stack)\n        \n        # Convert to tensors and apply any additional transformations\n        #images = [torch.tensor(img, dtype=torch.float32) for img in images]\n        samples = [{'T1': img, 'label': label} for img in images]\n\n        if self.transform:\n            samples = [self.transform(sample) for sample in samples]\n\n        return samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Transform samples to Tensor objects","metadata":{}},{"cell_type":"code","source":"class ToTensor(object):\n    def __call__(self, sample):\n        torch_sample = {}\n        for key, value in sample.items():\n        \tif key == 'label':\n        \t\ttorch_sample[key] = torch.from_numpy(np.array(value))\n        \telse:\n        \t\ttorch_sample[key] = torch.from_numpy(value)\n\n        return torch_sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Datasets","metadata":{}},{"cell_type":"code","source":"TrainDataDir = '../input/preprocessed-data/ADNI_large_sample/train/'\nValidationDataDir = '../input/preprocessed-data/ADNI_large_sample/validation/'\n\ntrain_dataset = MRIDataset(\n    DataDir=TrainDataDir, \n    mode='train', \n    input_T1=True,\n    transform=transforms.Compose([ToTensor()]), \n    T1_normalization_method='max', \n    downsample=1.5\n)\nvalidation_dataset = MRIDataset(\n    DataDir=ValidationDataDir, \n    mode='train', \n    input_T1=True,\n    transform=transforms.Compose([ToTensor()]), \n    T1_normalization_method='max', \n    downsample=1.5\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualize 3 channels of a test 2D Image","metadata":{}},{"cell_type":"code","source":"test = MRIDataset(\n    DataDir=TrainDataDir, \n    mode='train', \n    input_T1=True,\n    T1_normalization_method='max', \n    downsample=1.5\n)\nsamples = test[0]\n    \n# Choose the first 3-channel 2D image from the returned samples\nsample = samples[0]['T1']  # Assuming you want to visualize the first image from the batch\n\n# Extract the three channels\nchannel1 = sample[:, :, 0]\nchannel2 = sample[:, :, 1]\nchannel3 = sample[:, :, 2]\n\n# Plot each channel\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\naxes[0].imshow(channel1, cmap='gray')\naxes[0].set_title('Channel 1')\naxes[0].axis('off')\n\naxes[1].imshow(channel2, cmap='gray')\naxes[1].set_title('Channel 2')\naxes[1].axis('off')\n\naxes[2].imshow(channel3, cmap='gray')\naxes[2].set_title('Channel 3')\naxes[2].axis('off')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Store Datasets (to speed up training)## Create dataset and save it (to speed up training)","metadata":{}},{"cell_type":"code","source":"def preprocess_and_save_dataset(dataset, save_path):\n    \"\"\"\n    Preprocess a given dataset and save the processed data.\n    \"\"\"\n    os.makedirs(save_path, exist_ok=True)  # Ensure the save directory exists\n    \n    preprocessed_samples = []\n    for idx, sample in enumerate(dataset):\n        # Assuming your sample is a dictionary with 'T1' and 'label' keys\n        preprocessed_samples.append(sample)\n        \n        # Optionally, save individual samples to reduce memory usage\n        #torch.save(sample, os.path.join(save_path, f'sample_{idx}.pt'))\n\n    # Optionally, save the whole dataset as one file (if memory allows)\n    torch.save(preprocessed_samples, os.path.join(save_path, 'dataset.pt'))\n    \ndef load_preprocessed_data(preprocessed_path):\n    \"\"\"\n    Load preprocessed data from the given path.\n    \"\"\"\n    return torch.load(preprocessed_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocess_and_save_dataset(train_dataset, '../preprocessed_data/ADNI_large_sample/train_preprocessed/dataset.pt')\n#preprocess_and_save_dataset(validation_dataset, '/kaggle/working/val/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load datasets and create DataLoaders","metadata":{}},{"cell_type":"code","source":"batch_size = 1\n\npreprocessed_train_data = load_preprocessed_data('../preprocessed_data/ADNI_large_sample/train_preprocessed/dataset.pt/dataset.pt')\npreprocessed_validation_data = load_preprocessed_data('/kaggle/input/tensor-data/dataset.pt')\n\ntrain_dataloader = DataLoader(preprocessed_train_data, batch_size=batch_size,\n                              shuffle=True, num_workers=4)\nval_dataloader = DataLoader(preprocessed_validation_data, batch_size=batch_size,\n                            shuffle=False, num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (4) Define model","metadata":{}},{"cell_type":"markdown","source":"### VGG19 with Batch Normalization","metadata":{}},{"cell_type":"code","source":"# import torchvision.models as models\n\n# # Define VGG19 model pre-trained on ImageNet\n# vgg19 = models.vgg19(weights=\"IMAGENET1K_V1\") \n\n# # Determine which blocks to freeze - for example, freeze the first two blocks\n# blocks_to_freeze = 2\n# current_block = 0\n# for module in vgg19.features.children():\n#     if isinstance(module, nn.MaxPool2d):\n#         current_block += 1\n#     if current_block < blocks_to_freeze:\n#         for param in module.parameters():\n#             param.requires_grad = False\n\n# # Modify the last fully connected layer to match the number of classes in your dataset\n# num_classes = 2  # Example classes: AD (Alzheimer's Disease) and CN (Cognitively Normal)\n# vgg19.classifier[6] = nn.Linear(4096, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet18","metadata":{}},{"cell_type":"code","source":"# import torchvision.models as models\n# import torch.nn as nn\n\n# # Define ResNet18 model pre-trained on ImageNet\n# resnet18 = models.resnet18(weights=\"IMAGENET1K_V1\")\n\n# # Freeze the first two blocks of the ResNet50 model\n# blocks_to_freeze = 2\n# current_block = 0\n# for name, module in resnet18.named_children():\n#     if \"layer\" in name:\n#         current_block += 1\n#         if current_block <= blocks_to_freeze:\n#             for param in module.parameters():\n#                 param.requires_grad = False\n\n# # Modify the last fully connected layer to match the number of classes in your dataset\n# num_classes = 2  # Example classes: AD (Alzheimer's Disease) and CN (Cognitively Normal)\n# resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Swin Transformer","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import swin_t\n\n# Load pre-trained Swin Transformer\nswin = swin_t(weights=\"IMAGENET1K_V1\")\n\n# Freeze layers - you will need to adapt this part based on the output of the print statement\n# for example, it might be something like swin.patch_embed or layers within swin.layers\nfor name, param in swin.named_parameters():\n    # Assuming the blocks to be frozen are in early layers, freeze if condition met\n    if 'layer1' in name or 'layer2' in name:\n        param.requires_grad = False\n\n# Modify the classifier to match the number of classes\nnum_classes = 2  # Example classes: AD (Alzheimer's Disease) and CN (Cognitively Normal)\nswin.head = nn.Linear(swin.head.in_features, num_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (5) Define helper functions and paramters for training and validation","metadata":{}},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"#The performance on validation set has not improved for a while. Early stop. Training completed.\nclass EarlyStopChecker:\n    '''\n    Early stop checker. Credits to Chen \"Raphael\" Liu and Nanyan \"Rosalie\" Zhu.\n    '''\n    def __init__(self, search_window = 5, score_higher_better = True):\n        self.search_window = search_window\n        self.score_higher_better = score_higher_better\n        self.score_history = []\n\n    def __call__(self, current_score):\n        self.score_history.append(current_score)\n        if len(self.score_history) < 2 * self.search_window:\n            return False\n        else:\n            if self.score_higher_better == True:\n                if current_score < np.max(self.score_history) and np.mean(self.score_history[-self.search_window:]) < np.mean(self.score_history[-2*self.search_window:-self.search_window]):\n                    return True\n                else:\n                    return False\n            else:\n                if current_score > np.max(self.score_history) and np.mean(self.score_history[-self.search_window:]) > np.mean(self.score_history[-2*self.search_window:-self.search_window]):\n                    return True\n                else:\n                    return False\n                \nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy@k for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define loss function, early stop checker, and scheduler","metadata":{}},{"cell_type":"code","source":"#Defining the required variables\ncuda_idx = '0'\nmomentum = 0.9\nweight_decay = 5e-4\nlr = 1e-5\ndevice = torch.device(f\"cuda:{cuda_idx}\" if (torch.cuda.is_available()) else \"cpu\")\n\n# Define loss function (criterion) and optimizer\ncriterion = nn.CrossEntropyLoss()\ncriterion = criterion.to(device)\n\n# Initialize the checker for early stop\nearly_stop_checker = EarlyStopChecker()\n\noptimizer = torch.optim.SGD(swin.parameters(), lr,\n                            momentum=momentum,\n                            weight_decay=weight_decay)\n#Defining adaptive learning rate\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.8, patience = 2, verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Move model to GPU","metadata":{}},{"cell_type":"code","source":"# vgg19.to(device)\n# resnet18.to(device)\nswin.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define train and validation functions","metadata":{}},{"cell_type":"code","source":"data_dropout = True\ndata_dropout_remaining_size = 2000\ninput_T1 = True\n\ndef train(train_loader, model, criterion, optimizer, epoch, device):\n    \"\"\"\n    Run one train epoch\n    \"\"\"\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    model.train()\n    model_output_list, AD_ground_truth_list = [], []\n\n    end = time.time()\n\n    total_samples = sum(len(batch) for batch in train_loader)\n    print('Total samples in the training loader:', total_samples)\n\n    # If we use data dropout, sample a subset of indices from the total samples\n    if data_dropout:\n        sampled_indices = set(np.random.choice(range(total_samples), data_dropout_remaining_size, replace=False))\n        print(f'We will randomly sample {data_dropout_remaining_size} scans for this epoch from {total_samples} total samples.')\n\n    current_index = 0\n    for i, batch in enumerate(train_loader):\n        # Process each sample within the batch\n        for data in batch:\n            if data_dropout and current_index in sampled_indices:\n                input_data_T1 = data['T1'].to(device) if input_T1 else None\n                input_data_T1 = input_data_T1.permute(0, 3, 1, 2)\n                target = data['label'].to(device)\n\n                data_time.update(time.time() - end)\n\n                # compute output\n                output = model(input_data_T1)\n\n                loss = criterion(output, target)\n\n                # compute gradient and do SGD step\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                # Update metrics\n                output = output.float()\n                loss = loss.float()\n                acc1 = accuracy(output.data, target)[0]\n                losses.update(loss.item(), input_data_T1.size(0))\n                top1.update(acc1.item(), input_data_T1.size(0))\n\n                \n                model_output_list.append(output.data.cpu().detach().numpy().tolist())\n                AD_ground_truth_list.append(target.cpu().detach().numpy().tolist())\n                AD_prediction_list = [scipy.special.softmax(pred)[0][1] for pred in model_output_list]# measure sensitivity, specificity, AUC.\n\n            \n                # measure elapsed time\n                batch_time.update(time.time() - end)\n                end = time.time()\n            current_index += 1\n\n    \n    fpr, tpr, _ = roc_curve(AD_ground_truth_list, AD_prediction_list)\n    operating_point_index = np.argmax(1 - fpr + tpr)\n    sensitivity, specificity = tpr[operating_point_index], 1 - fpr[operating_point_index]\n    AUC = auc(fpr, tpr)            \n    print('\\nEpoch: [{0}][{1}/{2}]\\t'\n          'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n          'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n          'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n          'Accuracy@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n              epoch, i, len(train_loader), batch_time=batch_time,\n              data_time=data_time, loss=losses, top1=top1))\n    return [{'epoch': epoch,'loss': losses.avg, 'accuracy': top1.avg,'sensitivity': sensitivity,'specificity': specificity,'AUC': AUC}]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader, model, criterion, device, scheduler=None):\n    \"\"\"\n    Run evaluation\n    \"\"\"\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    top1 = AverageMeter()\n    val_display_counter = 0\n    model_output_list, AD_ground_truth_list = [], []\n\n    # switch to evaluate mode\n    model.eval()\n    end = time.time()\n    with torch.no_grad():\n        for i, batch in enumerate(val_loader):\n            \n            # Process each sub-batch\n            for data in batch:\n                input_data_T1 = data['T1']\n                if input_T1:\n                    input_data_T1 = input_data_T1.to(device)\n                    # Ensure the input tensor is correctly shaped [batch_size, channels, height, width]\n                    input_data_T1 = input_data_T1.permute(0, 3, 1, 2)\n\n                target = data['label'].to(device)\n\n                # measure data loading time\n                batch_time.update(time.time() - end)\n\n                # compute output\n                output = model(input_data_T1)\n                loss = criterion(output, target)\n\n                output = output.float()\n                loss = loss.float()\n\n                # measure accuracy and record loss\n                acc1 = accuracy(output.data, target)[0]\n                losses.update(loss.item(), input_data_T1.size(0))\n                top1.update(acc1.item(), input_data_T1.size(0))\n\n                # measure sensitivity, specificity, AUC.\n                model_output_list.append(output.data.cpu().detach().numpy().tolist())\n                AD_ground_truth_list.append(target.cpu().detach().numpy().tolist())\n                AD_prediction_list = [scipy.special.softmax(pred)[0][1] for pred in model_output_list]\n\n                \n                # measure elapsed time\n                batch_time.update(time.time() - end)\n                end = time.time()\n\n                \n\n    \n    fpr, tpr, _ = roc_curve(AD_ground_truth_list, AD_prediction_list)\n    operating_point_index = np.argmax(1 - fpr + tpr)\n    sensitivity, specificity = tpr[operating_point_index], 1 - fpr[operating_point_index]\n    AUC = auc(fpr, tpr)\n    print('\\n * Accuracy@1 {top1.avg:.3f}'.format(top1=top1))\n    print(' * Sensitivity {sensitivity:.3f} Specificity {specificity:.3f} AUC {AUC:.3f}'\n          .format(sensitivity=sensitivity, specificity=specificity, AUC=AUC))\n\n    # Optionally adjust learning rate based on validation loss\n    if scheduler:\n        scheduler.step(loss)\n\n    metrics_dict = {\n        'Time_Average': batch_time.avg,\n        'Loss_Average': losses.avg,\n        'Accuracy@1_Average': top1.avg,\n        'Sensitivity': sensitivity,\n        'Specificity': specificity,\n        'AUC': AUC\n    }\n    torch.cuda.empty_cache()\n\n    return top1.avg, AUC, [metrics_dict]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (6) Training Loop","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings('ignore')\nstart_epoch = 0\nepochs = 25\nbest_acc = 0\nbest_AUC = 0\n\nmetrics_to_save_all_epochs_train = []\nmetrics_to_save_all_epochs_val = []\nfor epoch in range(start_epoch, epochs):\n    # train for one epoch\n#     metrics_to_save_train = train(train_dataloader, resnet18, criterion, optimizer, epoch, device)\n    metrics_to_save_train = train(train_dataloader, swin, criterion, optimizer, epoch, device)\n    metrics_to_save_all_epochs_train.extend(metrics_to_save_train)\n\n    # evaluate on validation set\n#     current_acc, current_AUC, metrics_to_save_val = validate(val_dataloader, resnet18, criterion, device)\n    current_acc, current_AUC, metrics_to_save_val = validate(val_dataloader, swin, criterion, device)\n\n    # remember best acc@1 and save checkpoint\n    is_best = best_AUC < current_AUC\n    best_acc = max(current_acc, best_acc)\n    best_AUC = max(current_AUC, best_AUC)\n\n    metrics_to_save_all_epochs_val.extend(metrics_to_save_val)\n\n    if early_stop_checker(current_AUC):\n        print('The performance on validation set has not improved for a while. Early stop. Training completed.')\n        break\n\nkeys = metrics_to_save_all_epochs_train[0].keys()  # Get keys for the CSV column names from the first dictionary\ncsv_file_path = '/kaggle/working/training_metrics_train_downsample2.csv'  # Specify the Kaggle output path\nwith open(csv_file_path, 'w', newline='') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=keys)\n    writer.writeheader()\n    for data in metrics_to_save_all_epochs_train:\n        writer.writerow(data)\nkeys = metrics_to_save_all_epochs_val[0].keys()  # Get keys for the CSV column names from the first dictionary\ncsv_file_path = '/kaggle/working/training_metrics_val_downsample2.csv'  # Specify the Kaggle output path\nwith open(csv_file_path, 'w', newline='') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=keys)\n    writer.writeheader()\n    for data in metrics_to_save_all_epochs_val:\n        writer.writerow(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (7) Testing the model","metadata":{}},{"cell_type":"markdown","source":"### Create test dataset","metadata":{}},{"cell_type":"code","source":"TestDataDir = '../input/test-data/test/'\n\ntest_dataset = MRIDataset(\n    DataDir=TestDataDir, \n    mode='test', \n    input_T1=True,\n    transform=transforms.Compose([ToTensor()]), \n    T1_normalization_method='max', \n    downsample=1.5\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Store dataset, load it, and create Dataloader for testing","metadata":{}},{"cell_type":"code","source":"#preprocess_and_save_dataset(test_dataset, '/kaggle/working/test/')\npreprocessed_test_data = load_preprocessed_data('/kaggle/input/tensor-data/dataset-2.pt')\ntest_dataloader = DataLoader(preprocessed_test_data, batch_size=batch_size,\n                            shuffle=False, num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define test function","metadata":{}},{"cell_type":"code","source":"def test_model(test_loader, model, device):\n    model.eval()  # Set the model to evaluate mode\n    total_predictions = []\n    total_targets = []\n\n    with torch.no_grad():  # Turn off gradients for validation, saves memory and computations\n        for i, batch in enumerate(test_loader):\n            for data in batch:\n                input_data_T1 = data['T1'].to(device)\n                input_data_T1 = input_data_T1.permute(0, 3, 1, 2)  # Adjust dimensions as necessary\n                labels = data['label'].to(device)\n\n                outputs = model(input_data_T1)\n                _, predicted = torch.max(outputs.data, 1)\n\n                total_predictions.extend(predicted.cpu().numpy())\n                total_targets.extend(labels.cpu().numpy())\n\n    # Calculate performance metrics\n    fpr, tpr, thresholds = roc_curve(total_targets, total_predictions, pos_label=1)\n    AUC_score = auc(fpr, tpr)\n    sensitivity = tpr[np.argmax(1 - fpr + tpr)]\n    specificity = 1 - fpr[np.argmax(1 - fpr + tpr)]\n    accuracy = np.mean(np.array(total_targets) == np.array(total_predictions))\n\n    print(f'Accuracy: {accuracy}\\nSensitivity: {sensitivity}\\nSpecificity: {specificity}\\nAUC: {AUC_score}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print test results","metadata":{}},{"cell_type":"code","source":"test_model(test_dataloader, swin, device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}